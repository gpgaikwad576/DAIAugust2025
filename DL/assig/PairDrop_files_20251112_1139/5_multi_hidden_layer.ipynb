{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "feec610c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # Import NumPy for numerical computations and array operations\n",
    "import pandas as pd  # Import Pandas for data manipulation and analysis with DataFrames\n",
    "import matplotlib.pyplot as plt  # Import Matplotlib for creating static, interactive visualizations\n",
    "import seaborn as sns  # Import Seaborn for statistical data visualization built on Matplotlib\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split  # Import function to split dataset into training and testing subsets\n",
    "from sklearn.metrics import (accuracy_score, \n",
    "                             classification_report, \n",
    "                             confusion_matrix, \n",
    "                             ConfusionMatrixDisplay, \n",
    "                             f1_score)  # Import function to calculate various metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5dd26f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE=24\n",
    "np.random.seed(RANDOM_STATE)\n",
    "rng=np.random.default_rng(seed=RANDOM_STATE)\n",
    "\n",
    "TEST_SIZE=0.2\n",
    "NOISE=0.2\n",
    "EPOCHS=20000\n",
    "ALPHA=0.1\n",
    "N_SAMPLE=1000\n",
    "params={\"legend.fontsi\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d66ebef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y=make_moons(n_samples=N_SAMPLE,shuffle=True,noise=NOISE,random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f16dd0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.36493292704099645)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51d287b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=pd.get_dummies(y).to_numpy()\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35ce98e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.36493292704099645), np.float64(1.4654943925052067e-16))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "157f574c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((800, 2), (200, 2), (800, 2), (200, 2))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=TEST_SIZE,random_state=RANDOM_STATE)\n",
    "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fbfe121a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "s=StandardScaler()\n",
    "X_train=s.fit_transform(X_train)\n",
    "X_test=s.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1bb74db1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 2)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_hist={}\n",
    "# y_train=y_train.reshape(-1,1)\n",
    "param={}\n",
    "param[\"h_dim\"]=[X_train.shape[1],5,5,4,3,y_train.shape[1]]##No. of neurons in hidden layer\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "711382a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dai\\AppData\\Local\\Temp\\ipykernel_18148\\574927170.py:1: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(710)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(inf)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(710)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fb80d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_softmax(z):\n",
    "    exp_score=np.exp(z-np.max(z))\n",
    "    return exp_score/np.sum(exp_score,axis=1,keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ef02341a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1.])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm=fn_softmax(np.asarray([[-1,0,1.0],[-10,0,8]]))\n",
    "sm.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c614af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_activ(z):\n",
    "    return np.tanh(z)\n",
    "def fn_active_prime(z):\n",
    "    return 1.0 - np.tanh(z)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bf9dd67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model,X):\n",
    "    W1=model[\"W1\"]\n",
    "    W2=model[\"W2\"]\n",
    "    b1=model[\"b1\"]\n",
    "    b2=model[\"b2\"]\n",
    "\n",
    "    #Forward propogation\n",
    "    z1=X.dot(W1) + b1 #Aggregation\n",
    "    a1=fn_activ(z1) # Activation\n",
    "\n",
    "    z2=a1.dot(W2) + b2 #Aggregation\n",
    "    a2=fn_softmax(z2) # Activation\n",
    "\n",
    "    return a2>=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652378df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(model, X , y):\n",
    "    W1=model[\"W1\"]\n",
    "    W2=model[\"W2\"]\n",
    "    b1=model[\"b1\"]\n",
    "    b2=model[\"b2\"]\n",
    "\n",
    "    #Forward propogation\n",
    "    z1=X.dot(W1) + b1 #Aggregation\n",
    "    a1=fn_activ(z1) # Activation\n",
    "\n",
    "    z2=a1.dot(W2) + b2 #Aggregation\n",
    "    a2=fn_sigmoid(z2) # Activation\n",
    "\n",
    "    data_loss=-(y * np.log(a2) + (1-y)* np.log(1-a2)).sum()\n",
    "\n",
    "    return data_loss/X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cc24efc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def built_model(param,X_tr,y_tr,X_ts,y_ts,alpha,n_epoch):\n",
    "    m=X_tr.shape[0]\n",
    "    nn_output_dim=y.shape[1]\n",
    "    W1=rng.random((param[\"h_dim\"][0],param[\"h_dim\"][1]))/np.sqrt(param[\"h_dim\"][0])\n",
    "    W2=rng.random((param[\"h_dim\"][1],param[\"h_dim\"][2]))/np.sqrt(param[\"h_dim\"][1])\n",
    "    W3=rng.random((param[\"h_dim\"][2],param[\"h_dim\"][3]))/np.sqrt(param[\"h_dim\"][2])\n",
    "    W4=rng.random((param[\"h_dim\"][3],param[\"h_dim\"][4]))/np.sqrt(param[\"h_dim\"][3])\n",
    "    W5=rng.random((param[\"h_dim\"][4],param[\"h_dim\"][5]))/np.sqrt(param[\"h_dim\"][4])\n",
    "    \n",
    "    b1=np.zeros((1,param[\"h_dim\"][1]))\n",
    "    b2=np.zeros((1,param[\"h_dim\"][2]))\n",
    "    b3=np.zeros((1,param[\"h_dim\"][3]))\n",
    "    b4=np.zeros((1,param[\"h_dim\"][4]))\n",
    "    b5=np.zeros((1,param[\"h_dim\"][5]))\n",
    "    \n",
    "    \n",
    "    loss,epoch=[], []\n",
    "\n",
    "    for i in range(n_epoch):\n",
    "\n",
    "        #Forward propogation\n",
    "        z1=X_tr.dot(W1) + b1 #Aggregation\n",
    "        a1=fn_activ(z1) # Activation\n",
    "\n",
    "        z2=a1.dot(W2) + b2 #Aggregation\n",
    "        a2=fn_softmax(z2) # Activation\n",
    "\n",
    "        #Back Propogation\n",
    "\n",
    "        #Layer2\n",
    "        dz2=a2-y\n",
    "        assert (z2.shape == dz2.shape), f\"Shape z2: {z2.shape},{dz2.shape}\"\n",
    "\n",
    "        dW2=(a1.T).dot(dz2)\n",
    "        assert (W2.shape == dW2.shape), f\"Shape w2: {W2.shape},{dW2.shape}\"\n",
    "\n",
    "        db2=np.sum(dz2,axis=0,keepdims=True)\n",
    "        assert (b2.shape == db2.shape), f\"Shape b2: {b2.shape},{db2.shape}\"\n",
    "\n",
    "        da1=dz2.dot(W2.T)\n",
    "        assert (a1.shape == da1.shape), f\"Shape a2: {a2.shape},{da1.shape}\"\n",
    "\n",
    "        #Layer1\n",
    "        dz1=da1 * fn_active_prime(z1)\n",
    "        assert (z1.shape == dz1.shape), f\"Shape z1: {z1.shape},{dz1.shape}\"\n",
    "\n",
    "        dW1=(X_tr.T).dot(dz1)\n",
    "        assert (W1.shape == dW1.shape), f\"Shape W1: {W1.shape},{dW1.shape}\"\n",
    "\n",
    "        db1=np.sum(dz1,axis=0,keepdims=True)\n",
    "        assert (b1.shape == db1.shape), f\"Shape b1: {b1.shape},{db1.shape}\"\n",
    "\n",
    "        W1 = W1 - alpha * dW1/m\n",
    "        b1 = b1 - alpha * db1/m\n",
    "        W2 = W2 - alpha * dW2/m\n",
    "        b2 = b2 - alpha * db2/m\n",
    "\n",
    "        model={\"W1\":W1,\"W2\":W2,\"b1\":b1,\"b2\":b2}\n",
    "\n",
    "        if(i%100 == 0):\n",
    "            curr_loss = calculate_loss(model,X,y)\n",
    "            epoch.append(i)\n",
    "            loss.append(curr_loss)\n",
    "            print(f\"epoch - {i} : Loss - {curr_loss}\")\n",
    "    \n",
    "            loss_hist[\"epoch\"] = epoch\n",
    "            loss_hist[\"loss\"] = loss\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17e1e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=built_model(param,X_train,y_train,X_test,y_test,alpha=ALPHA,n_epoch=EPOCHS)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be6aa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_df=pd.DataFrame(loss_hist)\n",
    "loss_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c76570",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_df.plot(x=\"epoch\",y=\"loss\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb76d66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_plot_decision_boundary(X: np.ndarray, y :np.ndarray, model, pred_func):\n",
    "    \"\"\"\n",
    "    Plots the decision boundary for a classification model.\n",
    "\n",
    "    Args:\n",
    "        X: The input features (numpy array, expected shape (m, 2)).\n",
    "        y: The true labels (numpy array).\n",
    "        model: A dictionary containing the trained weights and biases (W1, W2, B1, B2).\n",
    "        pred_func: A function that takes the model and a feature array (XX) \n",
    "                   and returns the class predictions (0 or 1).\n",
    "    \"\"\"\n",
    "    # NOTE: The weights retrieval 'model.we' was incorrect and is removed.\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    \n",
    "    # Small increment value to create a fine grid for smooth decision boundary\n",
    "    dm = 0.05\n",
    "    padding = 0.5 # Increased padding for better visualization\n",
    "    \n",
    "    # Calculate the range for x-axis (first feature) with padding\n",
    "    x_min, x_max = X[:, 0].min() - padding, X[:, 0].max() + padding\n",
    "    \n",
    "    # Calculate the range for y-axis (second feature) with padding  \n",
    "    y_min, y_max = X[:, 1].min() - padding, X[:, 1].max() + padding\n",
    "    \n",
    "    # Create a mesh grid covering the entire feature space\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, dm),\n",
    "                         np.arange(y_min, y_max, dm))\n",
    "    \n",
    "    # Flatten the mesh grid arrays and stack them column-wise to create coordinate pairs\n",
    "    XX = np.c_[xx.ravel(), yy.ravel()] # Resulting shape: (n_points, 2)\n",
    "\n",
    "    # NOTE: The line 'XX = np.hstack((XX, np.ones((XX.shape[0], 1))))' is removed.\n",
    "    # The bias term is handled internally by the neural network's forward propagation \n",
    "    # (z1 = X.dot(w1) + b1), so the input data (XX) shouldn't be augmented with a column of ones.\n",
    "\n",
    "    # Make predictions for the entire mesh grid\n",
    "    # The pred_func should handle the forward pass through the model and return binary predictions.\n",
    "    y_p = pred_func(model, XX) \n",
    "    \n",
    "    # Reshape predictions to match the original mesh grid dimensions (xx.shape)\n",
    "    # y_p is expected to be a 1D array of predictions (0 or 1).\n",
    "    Z = np.array(y_p).reshape(xx.shape)\n",
    "\n",
    "    # Create filled contour plot showing the decision regions\n",
    "    # Use 'coolwarm' or 'bwr' for binary classification. 'Purples' is usually for single-class density.\n",
    "    ax.contourf(xx, yy, Z, alpha=0.6, cmap=plt.cm.coolwarm) \n",
    "    \n",
    "    # Scatter plot of the actual data points, colored by their true class labels\n",
    "    # Use 'y' for the color (true label) instead of X[:, 2] (which might not exist or be the label).\n",
    "    ax.scatter(X[:, 0], X[:, 1], c=y.flatten(), s=40, edgecolor='k', cmap=plt.cm.coolwarm) \n",
    "    \n",
    "    # Set plot title and axis labels\n",
    "    ax.set_title('Decision Boundary')\n",
    "    ax.set_xlabel('Feature 1')  \n",
    "    ax.set_ylabel('Feature 2') \n",
    "    \n",
    "    # Display the final plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5776a896",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_plot_decision_boundary(X, y, model, predict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
