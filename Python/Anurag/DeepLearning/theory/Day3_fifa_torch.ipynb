{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c9337ccd65cbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from matplotlib.font_manager import fontManager\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_moons\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix,ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "rng=np.random.default_rng(seed=42)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "# from utils.helper import fn_plot_torch_hist,fn_plot_confusion_matrix\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b939412e731487a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "###----------------------\n",
    "### Some basic parameters\n",
    "###----------------------\n",
    "\n",
    "inpDir = Path('..') / '..' / 'input'\n",
    "outDir = Path('..') / 'output'\n",
    "modelDir = Path('..') / 'models'\n",
    "subDir = 'fifa_2019'\n",
    "\n",
    "RANDOM_STATE = 24 # for initialization ----- REMEMBER: to remove at the time of promotion to production\n",
    "np.random.seed(RANDOM_STATE)\n",
    "rng = np.random.default_rng(seed = RANDOM_STATE) # Set Random Seed for reproducible  results\n",
    "\n",
    "EPOCHS = 100 # number of epochs\n",
    "BATCH_SIZE = 32\n",
    "ALPHA = 0.001 # learning rate\n",
    "TEST_SIZE = 0.2\n",
    "TRAIN_SIZE=454*BATCH_SIZE\n",
    "\n",
    "# parameters for Matplotlib\n",
    "params = {'legend.fontsize': 'x-large',\n",
    "          'figure.figsize': (15, 6),\n",
    "          'axes.labelsize': 'x-large',\n",
    "          'axes.titlesize':'x-large',\n",
    "          'xtick.labelsize':'x-large',\n",
    "          'ytick.labelsize':'x-large'\n",
    "         }\n",
    "\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "CMAP = plt.cm.coolwarm\n",
    "plt.style.use('seaborn-v0_8-darkgrid') # plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d123c6eba6242c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554f3b9632428e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if all directories are present\n",
    "outDir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "modelSubDir = modelDir/ subDir\n",
    "modelSubDir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12fc9e03b0ff28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(r\"D:\\dnn_input\\fifa_2019.csv\")\n",
    "data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3909ab99246bb9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing rows with position = null\n",
    "data_df = data_df[data_df[\"Position\"].notnull()]\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a850bfb05982b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cc454d340f294e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf733a71e59ab442",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.isna().sum()[data_df.isna().sum() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855bfd9e08f85513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following columns appear to be relevant for our analysis\n",
    "rel_cols = [\"Position\", 'Finishing', 'HeadingAccuracy', 'ShortPassing', 'Volleys', 'Dribbling',\n",
    "            'Curve', 'FKAccuracy', 'LongPassing', 'BallControl', 'Acceleration',\n",
    "            'SprintSpeed', 'Agility', 'Reactions', 'Balance', 'ShotPower',\n",
    "            'Jumping', 'Stamina', 'Strength', 'LongShots', 'Aggression',\n",
    "            'Interceptions', 'Positioning', 'Vision', 'Penalties', 'Composure',\n",
    "            'Marking', 'StandingTackle', 'SlidingTackle', 'GKDiving', 'GKHandling',\n",
    "            'GKKicking', 'GKPositioning', 'GKReflexes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4c521382b3c6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "goalkeeper = 'GK'\n",
    "forward = ['ST', 'LW', 'RW', 'LF', 'RF', 'RS','LS', 'CF']\n",
    "midfielder = ['CM','RCM','LCM', 'CDM','RDM','LDM', 'CAM', 'LAM', 'RAM', 'RM', 'LM']\n",
    "defender = ['CB', 'RCB', 'LCB', 'LWB', 'RWB', 'LB', 'RB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e7affb43fd9a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df=data_df[rel_cols]\n",
    "data_df=data_df[data_df['Position'].notnull()]\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da013f94b2579e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570a9419825521b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac30a1153ab4409",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in data_df.columns:\n",
    "    print(f'Col: {col} -{data_df[col].unique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db74bf914ced4fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90826d78492af43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign labels to goalkeepers\n",
    "data_df.loc[data_df[\"Position\"] == \"GK\", \"Position\"] = 0\n",
    "#Defenders\n",
    "data_df.loc[data_df[\"Position\"].isin(defender), \"Position\"] = 1\n",
    "#Midfielders\n",
    "data_df.loc[data_df[\"Position\"].isin(midfielder), \"Position\"] = 2\n",
    "#Forward\n",
    "data_df.loc[data_df[\"Position\"].isin(forward), \"Position\"] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf80d2af2f56c4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Column \"Position\" to numeric so that Pandas does not complain\n",
    "data_df['Position'] = pd.to_numeric(data_df['Position'], downcast=\"integer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99375af03d0efb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = {0: 'Goal Keeper', 1: 'Defender', 2: 'Mid-Fielder', 3: 'Forward'}\n",
    "\n",
    "labels=data_df['Position']\n",
    "features=data_df.drop('Position',axis=1)\n",
    "labels.shape,features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03b4de80739e892",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df,test_df=train_test_split(data_df,stratify=data_df[\"Position\"],train_size=TRAIN_SIZE,random_state=RANDOM_STATE)\n",
    "train_df.shape,test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618a42f3893429be",
   "metadata": {},
   "source": [
    "## Custom DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1ca0942044bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalScaler:\n",
    "    _instance=None\n",
    "\n",
    "    def __init__(self):\n",
    "        if GlobalScaler._instance is not None:\n",
    "            raise Exception(\"GlobalScaler is Singleton Class\")\n",
    "        self.scaler=StandardScaler()\n",
    "\n",
    "    @classmethod\n",
    "    def get_instance(cls):\n",
    "        if cls._instance is None:\n",
    "            cls._instance=GlobalScaler()\n",
    "        return cls._instance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fa20cda460887d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FifaDS(Dataset):\n",
    "    globalScaler=GlobalScaler.get_instance() #Protected Variable\n",
    "\n",
    "    def __init__(self,dataframe,device=device,is_train=True,label_col=None):\n",
    "        self.df=dataframe\n",
    "        self.device=device\n",
    "        self.is_train=is_train\n",
    "        self.scaler=self.globalScaler.scaler\n",
    "        self.label_col=label_col\n",
    "    \n",
    "        self.labels=self.df[label_col].to_numpy()\n",
    "        if self.is_train:\n",
    "            X=self.df.drop(label_col,axis=1)\n",
    "            self.features=self.scaler.fit_transform(X)\n",
    "        else:\n",
    "            X=self.df.drop(label_col,axis=1)\n",
    "            self.features=self.scaler.transform(X)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        feature=self.features[index]\n",
    "        label=self.labels[index]\n",
    "        # return super().__getitem__(index)\n",
    "\n",
    "        feature = torch.tensor(feature,dtype=torch.float32,device=self.device)\n",
    "        label = torch.tensor(label,dtype=torch.int64,device=self.device)\n",
    "        return feature,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1757a9babf30b46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = FifaDS(train_df,is_train=True,label_col=\"Position\")\n",
    "test_ds = FifaDS(test_df,is_train=True,label_col=\"Position\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9940a39602740a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_ds,batch_size=BATCH_SIZE,shuffle=True)\n",
    "test_loader = DataLoader(test_ds,batch_size=BATCH_SIZE,shuffle=True)\n",
    "\n",
    "\n",
    "for count,data in enumerate(test_loader):\n",
    "    feast, lbs =data\n",
    "    print(f'count:{count} featues:{feast.shape}  labels:{lbs}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa02e6862a6cdb8",
   "metadata": {},
   "source": [
    "## MOdel Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f859a5d24f902ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self,input_dim):\n",
    "        super().__init__()\n",
    "        dim_1 = 66\n",
    "\n",
    "        self.layer1 = nn.Linear(input_dim,dim_1)\n",
    "        self.activ1 = nn.ReLU()                 ##  output 66\n",
    "\n",
    "        dim_2 = 33\n",
    "        self.layer2 = nn.Linear(dim_1,dim_2)\n",
    "        self.activ2 = nn.ReLU()                 ##  output 33\n",
    "\n",
    "        dim_3 = 16\n",
    "        self.layer3 = nn.Linear(dim_2,dim_3)\n",
    "        self.activ3 = nn.ReLU()                 ##  output 16\n",
    "\n",
    "        dim_4 = 8\n",
    "        self.layer4 = nn.Linear(dim_3,dim_4)\n",
    "        self.activ4 = nn.ReLU()                 ##  output 8\n",
    "\n",
    "        output_dim = 4\n",
    "        self.layer5 = nn.Linear(dim_4,output_dim)  ## Output 4\n",
    "        # self.activ5 = nn.LogSigmoid(dim =1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.activ1(self.layer1(x))\n",
    "        x = self.activ2(self.layer2(x))\n",
    "        x = self.activ3(self.layer3(x))\n",
    "        x = self.activ4(self.layer4(x))\n",
    "        x = self.layer5(x)\n",
    "        return x\n",
    "\n",
    "model =Model(input_dim=33).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd79edfd6f37f606",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba94923fc28a3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f497aa246211b616",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cProfile import label\n",
    "\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=ALPHA)\n",
    "\n",
    "loss,tloss,acc,tacc,n_epoch=[],[],[],[],[]\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "\n",
    "    ## Train\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs,labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        pred = torch.argmax(outputs,dim=1)\n",
    "\n",
    "        batch_loss = loss_fn(outputs,labels)\n",
    "        batch_acc = accuracy_score(labels.cpu().numpy(),pred.cpu().numpy())\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss+=batch_loss.item()*inputs.size(0)\n",
    "        train_acc+=batch_acc*inputs.size(0)\n",
    "\n",
    "    train_loss=train_loss/len(train_ds)\n",
    "    loss.append(train_loss)\n",
    "\n",
    "    train_acc = train_acc/len(train_ds)\n",
    "    acc.append(train_acc)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        test_acc = 0.0\n",
    "\n",
    "        ## Test\n",
    "        for i, data in enumerate(test_loader):\n",
    "            inputs,labels = data\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            pred = torch.argmax(outputs,dim=1)\n",
    "\n",
    "            batch_loss = loss_fn(outputs,labels)\n",
    "            batch_acc = accuracy_score(labels.cpu().numpy(),pred.cpu().numpy())\n",
    "\n",
    "\n",
    "            test_loss+=batch_loss.item()*inputs.size(0)\n",
    "            test_acc+=batch_acc*inputs.size(0)\n",
    "\n",
    "        test_loss = test_loss/len(test_ds)\n",
    "        test_acc = test_acc/len(test_ds)\n",
    "\n",
    "        tloss.append(test_loss)\n",
    "        tacc.append(test_acc)\n",
    "\n",
    "    n_epoch.append(epoch)\n",
    "    if epoch%10==0:\n",
    "        print(f\"Epoch:{epoch}|Loss:{train_loss:.4f}-Test_loss{test_loss:.4f} | Acc:{train_acc:.4f}-test_acc{test_acc:.4f}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0ee56f0d8e2154",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(loss),len(tloss),len(acc),len(tacc),len(n_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d83e1cca4a2419",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df=pd.DataFrame(data={'loss':loss,\"val_loss\":tloss,\"accuracy\":acc,'val_accuracy':tacc,'epoch':n_epoch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857e6a66b74ffee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,2,figsize=(15,8))\n",
    "ax[0].plot(result_df.epoch,result_df['accuracy'],label='accuracy')\n",
    "ax[0].plot(result_df.epoch,result_df['val_accuracy'],label='val_accuracy')\n",
    "ax[0].set_title('Accuracy')\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].set_ylabel('Accuracy')\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(result_df.epoch,result_df['loss'],label='loss')\n",
    "ax[1].plot(result_df.epoch,result_df['val_loss'],label='val_loss')\n",
    "ax[1].set_title('Loss')\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].set_ylabel('loss')\n",
    "ax[1].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc0f25b46d2d565",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7292ec25a2acbbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678f602eff1f83b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
