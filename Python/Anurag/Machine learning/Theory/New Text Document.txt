import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder
from sklearn.linear_model import LogisticRegression
import numpy as np

# --- 1. Create a dummy dataset ---
data = {
    'Age': [35, 45, 20, np.nan, 55, 30],
    'Salary': [50000, 75000, 30000, 60000, 100000, 40000],
    'Gender': ['Male', 'Female', 'Female', 'Male', 'Female', 'Male'],
    'Education': ['High', 'College', 'Low', 'College', 'High', 'Low'], # Ordinal
    'Target': [0, 1, 0, 1, 1, 0]
}
df = pd.DataFrame(data)
X = df.drop('Target', axis=1)
y = df['Target']

# Separate feature types
numerical_features = ['Age', 'Salary']
categorical_nominal_features = ['Gender']
categorical_ordinal_features = ['Education']

# Define the order of the ordinal categories
education_categories = [['Low', 'High', 'College']] # Note: This assumes High < College (example only)

# --- 2. Define Preprocessing Pipelines (Transformers) ---

# Pipeline for numerical features: impute missing values then scale
numerical_pipeline = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='mean')),
    ('scaler', StandardScaler())
])

# Pipeline for nominal (non-ordered) categorical features: impute then one-hot encode
categorical_nominal_pipeline = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),
    ('onehot', OneHotEncoder(handle_unknown='ignore'))
])

# Pipeline for ordinal (ordered) categorical features: impute then ordinal encode
categorical_ordinal_pipeline = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),
    ('ordinal', OrdinalEncoder(categories=education_categories))
])

# --- 3. Combine Pipelines using ColumnTransformer ---
preprocessor = ColumnTransformer(
    transformers=[
        ('num', numerical_pipeline, numerical_features),
        ('cat_nom', categorical_nominal_pipeline, categorical_nominal_features),
        ('cat_ord', categorical_ordinal_pipeline, categorical_ordinal_features)
    ],
    remainder='passthrough' # Keep other columns untouched (none in this case)
)

# --- 4. Create the Final Model Pipeline ---
# Chain the preprocessor and the final estimator (e.g., Logistic Regression)
model_pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', LogisticRegression())
])

# --- 5. Training and Prediction ---
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Fit the entire pipeline
model_pipeline.fit(X_train, y_train)

# Transform the test data and predict
y_pred = model_pipeline.predict(X_test)
score = model_pipeline.score(X_test, y_test)

print("Original Data:")
print(X_train)
print("-" * 30)

# You can examine the transformed data by calling fit_transform on the preprocessor
X_train_transformed = preprocessor.fit_transform(X_train)
print("Transformed Data Shape:", X_train_transformed.shape)
print("First transformed sample (features):")
print(X_train_transformed[0])
print("-" * 30)

print(f"Model Score: {score:.2f}")